{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bb26ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\bolit\\appdata\\roaming\\python\\python39\\site-packages (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.19.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (61.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (21.3)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\bolit\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.27.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\bolit\\anaconda3\\lib\\site-packages (from packaging->tensorflow-gpu) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce15e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "per_process_gpu_memory_fraction: 0.333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats, interpolate\n",
    "import os\n",
    "from tensorflow.keras import backend as K  \n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.333)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4883efc",
   "metadata": {},
   "source": [
    "## dataset read and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f180005",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data=pd.read_hdf(\"/Users/bolit/OneDrive/Documentos/Tec/7_semestre/investigacion/CWoaLaSimulation/content/events_anomalydetection_v2.features.h5\")\n",
    "features_sig=original_data.query(\"label == 1\")\n",
    "features_bg=original_data.query(\"label == 0\")\n",
    "\n",
    "\n",
    "features_bg2=pd.read_hdf(\"/Users/bolit/OneDrive/Documentos/Tec/7_semestre/investigacion/CWoaLaSimulation/content/events_anomalydetection_DelphesHerwig_qcd_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40cec6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pxj1</th>\n",
       "      <th>pyj1</th>\n",
       "      <th>pzj1</th>\n",
       "      <th>mj1</th>\n",
       "      <th>tau1j1</th>\n",
       "      <th>tau2j1</th>\n",
       "      <th>tau3j1</th>\n",
       "      <th>pxj2</th>\n",
       "      <th>pyj2</th>\n",
       "      <th>pzj2</th>\n",
       "      <th>mj2</th>\n",
       "      <th>tau1j2</th>\n",
       "      <th>tau2j2</th>\n",
       "      <th>tau3j2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000000</th>\n",
       "      <td>-1698.670044</td>\n",
       "      <td>-884.039978</td>\n",
       "      <td>723.843018</td>\n",
       "      <td>105.035004</td>\n",
       "      <td>83.721703</td>\n",
       "      <td>46.282101</td>\n",
       "      <td>13.635600</td>\n",
       "      <td>1539.439941</td>\n",
       "      <td>372.238007</td>\n",
       "      <td>-295.865997</td>\n",
       "      <td>461.574005</td>\n",
       "      <td>431.343994</td>\n",
       "      <td>52.344799</td>\n",
       "      <td>37.284901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000001</th>\n",
       "      <td>1246.660034</td>\n",
       "      <td>-1133.010010</td>\n",
       "      <td>-921.987000</td>\n",
       "      <td>159.865997</td>\n",
       "      <td>133.781998</td>\n",
       "      <td>58.968601</td>\n",
       "      <td>30.377399</td>\n",
       "      <td>-1218.489990</td>\n",
       "      <td>1108.380005</td>\n",
       "      <td>182.147003</td>\n",
       "      <td>514.883972</td>\n",
       "      <td>462.654999</td>\n",
       "      <td>138.789001</td>\n",
       "      <td>67.805801</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000002</th>\n",
       "      <td>420.975006</td>\n",
       "      <td>-1739.790039</td>\n",
       "      <td>281.553986</td>\n",
       "      <td>93.665802</td>\n",
       "      <td>77.925797</td>\n",
       "      <td>10.605900</td>\n",
       "      <td>6.916510</td>\n",
       "      <td>-510.779999</td>\n",
       "      <td>1484.069946</td>\n",
       "      <td>227.175995</td>\n",
       "      <td>475.316986</td>\n",
       "      <td>217.113998</td>\n",
       "      <td>29.424000</td>\n",
       "      <td>21.020300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000003</th>\n",
       "      <td>161.048996</td>\n",
       "      <td>-1664.859985</td>\n",
       "      <td>-2005.099976</td>\n",
       "      <td>116.327003</td>\n",
       "      <td>61.819698</td>\n",
       "      <td>38.143600</td>\n",
       "      <td>18.414400</td>\n",
       "      <td>-188.942993</td>\n",
       "      <td>1556.900024</td>\n",
       "      <td>-561.664001</td>\n",
       "      <td>561.236023</td>\n",
       "      <td>348.179993</td>\n",
       "      <td>102.625000</td>\n",
       "      <td>53.422699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000004</th>\n",
       "      <td>-564.754028</td>\n",
       "      <td>-1315.599976</td>\n",
       "      <td>-1087.410034</td>\n",
       "      <td>513.015991</td>\n",
       "      <td>276.446991</td>\n",
       "      <td>50.629799</td>\n",
       "      <td>35.460999</td>\n",
       "      <td>326.164001</td>\n",
       "      <td>1050.239990</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>108.752998</td>\n",
       "      <td>89.666603</td>\n",
       "      <td>40.928699</td>\n",
       "      <td>17.055799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099995</th>\n",
       "      <td>1069.660034</td>\n",
       "      <td>659.874023</td>\n",
       "      <td>218.751007</td>\n",
       "      <td>126.183998</td>\n",
       "      <td>122.486000</td>\n",
       "      <td>27.608700</td>\n",
       "      <td>17.924801</td>\n",
       "      <td>-956.169006</td>\n",
       "      <td>-297.311005</td>\n",
       "      <td>-2204.350098</td>\n",
       "      <td>108.889999</td>\n",
       "      <td>21.177299</td>\n",
       "      <td>10.582400</td>\n",
       "      <td>9.138600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099996</th>\n",
       "      <td>-1286.619995</td>\n",
       "      <td>-86.162498</td>\n",
       "      <td>-1366.270020</td>\n",
       "      <td>115.719002</td>\n",
       "      <td>109.853996</td>\n",
       "      <td>29.830200</td>\n",
       "      <td>22.489201</td>\n",
       "      <td>1145.729980</td>\n",
       "      <td>136.792007</td>\n",
       "      <td>1216.780029</td>\n",
       "      <td>489.053009</td>\n",
       "      <td>416.747009</td>\n",
       "      <td>84.599998</td>\n",
       "      <td>66.767502</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099997</th>\n",
       "      <td>-149.330002</td>\n",
       "      <td>1781.459961</td>\n",
       "      <td>-58.690899</td>\n",
       "      <td>508.045013</td>\n",
       "      <td>495.290985</td>\n",
       "      <td>82.283600</td>\n",
       "      <td>43.567902</td>\n",
       "      <td>84.726700</td>\n",
       "      <td>-1378.569946</td>\n",
       "      <td>-1485.469971</td>\n",
       "      <td>91.104897</td>\n",
       "      <td>79.120102</td>\n",
       "      <td>46.537300</td>\n",
       "      <td>23.227301</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099998</th>\n",
       "      <td>1584.699951</td>\n",
       "      <td>-731.156982</td>\n",
       "      <td>-196.348007</td>\n",
       "      <td>114.938004</td>\n",
       "      <td>83.769897</td>\n",
       "      <td>12.898200</td>\n",
       "      <td>9.031230</td>\n",
       "      <td>-1515.079956</td>\n",
       "      <td>783.245972</td>\n",
       "      <td>498.704010</td>\n",
       "      <td>553.737000</td>\n",
       "      <td>366.188995</td>\n",
       "      <td>192.139008</td>\n",
       "      <td>81.398201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099999</th>\n",
       "      <td>-1229.599976</td>\n",
       "      <td>-1009.890015</td>\n",
       "      <td>1105.800049</td>\n",
       "      <td>154.110992</td>\n",
       "      <td>95.494904</td>\n",
       "      <td>76.178902</td>\n",
       "      <td>57.348499</td>\n",
       "      <td>1253.589966</td>\n",
       "      <td>967.965027</td>\n",
       "      <td>-233.518005</td>\n",
       "      <td>421.441986</td>\n",
       "      <td>238.966003</td>\n",
       "      <td>130.369995</td>\n",
       "      <td>88.144096</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                pxj1         pyj1         pzj1         mj1      tau1j1  \\\n",
       "1000000 -1698.670044  -884.039978   723.843018  105.035004   83.721703   \n",
       "1000001  1246.660034 -1133.010010  -921.987000  159.865997  133.781998   \n",
       "1000002   420.975006 -1739.790039   281.553986   93.665802   77.925797   \n",
       "1000003   161.048996 -1664.859985 -2005.099976  116.327003   61.819698   \n",
       "1000004  -564.754028 -1315.599976 -1087.410034  513.015991  276.446991   \n",
       "...              ...          ...          ...         ...         ...   \n",
       "1099995  1069.660034   659.874023   218.751007  126.183998  122.486000   \n",
       "1099996 -1286.619995   -86.162498 -1366.270020  115.719002  109.853996   \n",
       "1099997  -149.330002  1781.459961   -58.690899  508.045013  495.290985   \n",
       "1099998  1584.699951  -731.156982  -196.348007  114.938004   83.769897   \n",
       "1099999 -1229.599976 -1009.890015  1105.800049  154.110992   95.494904   \n",
       "\n",
       "            tau2j1     tau3j1         pxj2         pyj2         pzj2  \\\n",
       "1000000  46.282101  13.635600  1539.439941   372.238007  -295.865997   \n",
       "1000001  58.968601  30.377399 -1218.489990  1108.380005   182.147003   \n",
       "1000002  10.605900   6.916510  -510.779999  1484.069946   227.175995   \n",
       "1000003  38.143600  18.414400  -188.942993  1556.900024  -561.664001   \n",
       "1000004  50.629799  35.460999   326.164001  1050.239990  1201.000000   \n",
       "...            ...        ...          ...          ...          ...   \n",
       "1099995  27.608700  17.924801  -956.169006  -297.311005 -2204.350098   \n",
       "1099996  29.830200  22.489201  1145.729980   136.792007  1216.780029   \n",
       "1099997  82.283600  43.567902    84.726700 -1378.569946 -1485.469971   \n",
       "1099998  12.898200   9.031230 -1515.079956   783.245972   498.704010   \n",
       "1099999  76.178902  57.348499  1253.589966   967.965027  -233.518005   \n",
       "\n",
       "                mj2      tau1j2      tau2j2     tau3j2  label  \n",
       "1000000  461.574005  431.343994   52.344799  37.284901    1.0  \n",
       "1000001  514.883972  462.654999  138.789001  67.805801    1.0  \n",
       "1000002  475.316986  217.113998   29.424000  21.020300    1.0  \n",
       "1000003  561.236023  348.179993  102.625000  53.422699    1.0  \n",
       "1000004  108.752998   89.666603   40.928699  17.055799    1.0  \n",
       "...             ...         ...         ...        ...    ...  \n",
       "1099995  108.889999   21.177299   10.582400   9.138600    1.0  \n",
       "1099996  489.053009  416.747009   84.599998  66.767502    1.0  \n",
       "1099997   91.104897   79.120102   46.537300  23.227301    1.0  \n",
       "1099998  553.737000  366.188995  192.139008  81.398201    1.0  \n",
       "1099999  421.441986  238.966003  130.369995  88.144096    1.0  \n",
       "\n",
       "[100000 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c013d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "def load_dataT21(input_frame):\n",
    "    dataset = input_frame[[\"mj1\",\"tau1j1\",\"tau2j1\",\"mj2\",\"tau1j2\",\"tau2j2\"]]\n",
    "    dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
    "    dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
    "    dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
    "\n",
    "    dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau21jOne\"] = dataset[\"tau2jOne\"]/dataset[\"tau1jOne\"]\n",
    "    dataset[\"tau21jTwo\"] = dataset[\"tau2jTwo\"]/dataset[\"tau1jTwo\"]\n",
    "    dataset[\"mjTwo\"] = dataset[\"mjTwo\"]/1000. + 2*alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjOne\"] = dataset[\"mjOne\"]/1000. + alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjDelta\"] = (dataset[\"mjTwo\"] - dataset[\"mjOne\"])\n",
    "\n",
    "    dataset = dataset.fillna(0)\n",
    "    dataset = dataset[[\"mjj\",\"mjOne\",\"mjDelta\", \"tau21jOne\", \"tau21jTwo\"]]\n",
    "    return dataset.to_numpy()\n",
    "\n",
    "def load_dataT32(input_frame):\n",
    "    dataset = input_frame[[\"mj1\",\"tau1j1\",\"tau2j1\",\"mj2\",\"tau1j2\",\"tau2j2\",\"tau3j1\",\"tau3j2\"]]\n",
    "    dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
    "    dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
    "    dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
    "\n",
    "    dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau3jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n",
    "    dataset[\"tau3jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n",
    "    dataset[\"tau32jOne\"] = dataset[\"tau3jOne\"]/dataset[\"tau2jOne\"]\n",
    "    dataset[\"tau32jTwo\"] = dataset[\"tau3jTwo\"]/dataset[\"tau2jTwo\"] \n",
    "    dataset[\"mjTwo\"] = dataset[\"mjTwo\"]/1000. + 2*alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjOne\"] = dataset[\"mjOne\"]/1000. + alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjDelta\"] = (dataset[\"mjTwo\"] - dataset[\"mjOne\"])\n",
    "\n",
    "    dataset = dataset.fillna(0)\n",
    "    dataset = dataset[[\"mjj\",\"mjOne\",\"mjDelta\", \"tau32jOne\", \"tau32jTwo\"]]\n",
    "    return dataset.to_numpy()\n",
    "\n",
    "def load_data_more(input_frame):\n",
    "    dataset = input_frame[[\"mj1\",\"tau1j1\",\"tau2j1\",\"mj2\",\"tau1j2\",\"tau2j2\",\"tau3j1\",\"tau3j2\"]]\n",
    "    \n",
    "    #Masa ya al cuadrado\n",
    "    dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
    "    \n",
    "    \n",
    "    dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
    "    dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
    "\n",
    "    dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
    "    dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
    "    dataset[\"tau21jOne\"] = dataset[\"tau2jOne\"]/dataset[\"tau1jOne\"]\n",
    "    dataset[\"tau21jTwo\"] = dataset[\"tau2jTwo\"]/dataset[\"tau1jTwo\"]\n",
    "    \n",
    "    #tau32\n",
    "    dataset[\"tau3jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n",
    "    dataset[\"tau3jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n",
    "    dataset[\"tau32jOne\"] = dataset[\"tau3jOne\"]/dataset[\"tau2jOne\"]\n",
    "    dataset[\"tau32jTwo\"] = dataset[\"tau3jTwo\"]/dataset[\"tau2jTwo\"]   \n",
    "    \n",
    "    #pT\n",
    "    dataset[\"pT1\"] = (input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2)**0.5/1000.\n",
    "    dataset[\"pT2\"] = (input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2)**0.5/1000.\n",
    "    dataset[\"pTjOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"pT1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"pT2\"]\n",
    "    dataset[\"pTjTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"pT1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"pT2\"]    \n",
    "    \n",
    "    #eta\n",
    "    dataset[\"E1\"] = ((1000*dataset[\"pT1\"])**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5/1000.\n",
    "    dataset[\"E2\"] = ((1000*dataset[\"pT2\"])**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5/1000.\n",
    "    dataset[\"y1\"] = 0.5*np.log((dataset[\"E1\"] + input_frame[\"pzj1\"]/1000.)/(dataset[\"E1\"] - input_frame[\"pzj1\"]/1000.))\n",
    "    dataset[\"y2\"] = 0.5*np.log((dataset[\"E2\"] + input_frame[\"pzj2\"]/1000.)/(dataset[\"E2\"] - input_frame[\"pzj2\"]/1000.))\n",
    "    dataset[\"Dy\"] = dataset[\"y1\"]-dataset[\"y2\"]\n",
    "    \n",
    "    dataset[\"mjTwo\"] = dataset[\"mjTwo\"]/1000. + 2*alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjOne\"] = dataset[\"mjOne\"]/1000. + alpha*dataset[\"mjj\"]\n",
    "    dataset[\"mjDelta\"] = (dataset[\"mjTwo\"] - dataset[\"mjOne\"])\n",
    "\n",
    "    dataset = dataset.fillna(0)\n",
    "    dataset = dataset[[\"mjj\",\"mjOne\",\"mjDelta\", \"tau21jOne\", \"tau21jTwo\", \"tau32jOne\", \"tau32jTwo\",\"pTjOne\",\"pTjTwo\",\"Dy\"]]\n",
    "    return dataset.to_numpy()\n",
    "\n",
    "column_labelsT21 = [\n",
    "    r\"$m_{JJ}$\",\n",
    "    r\"$m^{J_1}$\",\n",
    "    \"$m^{J_2} - m^{J_1}$\",\n",
    "    r\"$\\tau_{2,1}^{J_1}$\", \n",
    "    r\"$\\tau_{2,1}^{J_2}$\",\n",
    "]\n",
    "\n",
    "column_labelsT32 = [\n",
    "    r\"$m_{JJ}$\",\n",
    "    r\"$m^{J_1}$\",\n",
    "    \"$m^{J_2} - m^{J_1}$\",\n",
    "    r\"$\\tau_{3,2}^{J_1}$\", \n",
    "    r\"$\\tau_{3,2}^{J_2}$\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6763ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau21jOne\"] = dataset[\"tau2jOne\"]/dataset[\"tau1jOne\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau21jOne\"] = dataset[\"tau2jOne\"]/dataset[\"tau1jOne\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau3jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau3jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau3j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau3j2\"]\n"
     ]
    }
   ],
   "source": [
    "dataset_bgT21=load_dataT21(features_bg)\n",
    "dataset_bg2T21=load_dataT21(features_bg2)\n",
    "dataset_sigT21=load_dataT21(features_sig)\n",
    "\n",
    "dataset_bgT32=load_dataT32(features_bg)\n",
    "dataset_bg2T32=load_dataT32(features_bg2)\n",
    "dataset_sigT32=load_dataT32(features_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a454916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjj\"] = (((input_frame[\"pxj1\"]**2+input_frame[\"pyj1\"]**2+input_frame[\"pzj1\"]**2+input_frame[\"mj1\"]**2)**0.5+(input_frame[\"pxj2\"]**2+input_frame[\"pyj2\"]**2+input_frame[\"pzj2\"]**2+input_frame[\"mj2\"]**2)**0.5)**2-(input_frame[\"pxj1\"]+input_frame[\"pxj2\"])**2-(input_frame[\"pyj1\"]+input_frame[\"pyj2\"])**2-(input_frame[\"pzj1\"]+input_frame[\"pzj2\"])**2)**0.5/1000.\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjTwo\"] = dataset[[\"mj1\", \"mj2\"]].max(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"mjOne\"] = dataset[[\"mj1\", \"mj2\"]].min(axis=1)\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau2jOne\"] = (dataset[\"mjOne\"] == dataset[\"mj1\"])*dataset[\"tau2j1\"]+(dataset[\"mjOne\"] == dataset[\"mj2\"])*dataset[\"tau2j2\"]\n",
      "C:\\Users\\bolit\\AppData\\Local\\Temp\\ipykernel_18460\\259476259.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"tau1jTwo\"] = (dataset[\"mjTwo\"] == dataset[\"mj1\"])*dataset[\"tau1j1\"]+(dataset[\"mjTwo\"] == dataset[\"mj2\"])*dataset[\"tau1j2\"]\n"
     ]
    }
   ],
   "source": [
    "dataset_bg_more=load_data_more(features_bg)\n",
    "dataset_bg2_more=load_data_more(features_bg2)\n",
    "dataset_sig_more=load_data_more(features_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba207f0",
   "metadata": {},
   "source": [
    "## data preparation CWoLa T_21\n",
    "\n",
    "making it machine-learnable, setting params for ML methods, setting signal significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04edcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True ...  True  True  True]\n",
      "     # signal events:  1000\n",
      " signal significance:  4.059677443835412\n",
      "           s/b ratio:  0.016480980947986026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SR_low = 3.3\n",
    "SR_high = 3.7\n",
    "test_size = 0.5\n",
    "EPOCHS=20\n",
    "batch_size = 200\n",
    "\n",
    "def sr_crit(d):\n",
    "    return (d[:,0] < SR_high) & (d[:,0] >= SR_low)\n",
    "\n",
    "bg_srsbT21, bg2_srsbT21, sig_srsbT21 = sr_crit(dataset_bgT21), sr_crit(dataset_bg2T21), sr_crit(dataset_sigT21)\n",
    "\n",
    "SR_background_dataT21 = dataset_bgT21[bg_srsbT21]\n",
    "SB_background_dataT21 = dataset_bgT21[~bg_srsbT21]\n",
    "print(~bg_srsbT21)\n",
    "\n",
    "SR_background_simT21 = dataset_bg2T21[bg2_srsbT21]\n",
    "SB_background_simT21 = dataset_bg2T21[~bg2_srsbT21]\n",
    "\n",
    "SR_signalT21 = dataset_sigT21[sig_srsbT21]\n",
    "SB_signalT21 = dataset_sigT21[~sig_srsbT21]\n",
    "\n",
    "N_inputs = len(SR_background_dataT21.T) - 1\n",
    "\n",
    "\n",
    "((SR_background_dataT21, SR_background_data_fortestT21),\n",
    " (SR_background_simT21, SR_background_sim_fortestT21),\n",
    " (SB_background_dataT21, SB_background_data_fortestT21),\n",
    " (SB_background_simT21, SB_background_sim_fortestT21),\n",
    " ) = [train_test_split(arr, test_size=test_size) for arr in [\n",
    "    SR_background_dataT21, SR_background_simT21,\n",
    "    SB_background_dataT21, SB_background_simT21,\n",
    "]]\n",
    "\n",
    "mn,mx = np.percentile(np.concatenate([SB_background_dataT21, SB_background_simT21, SR_background_dataT21, \n",
    "                                      SR_background_simT21]), [1,99], axis=0)\n",
    "\n",
    "def norm_func(d):\n",
    "    return (d - mn)/(mx - mn)\n",
    "\n",
    "Nsig = 1000\n",
    "Nsig_SB = int(np.round(len(SB_signalT21)*Nsig/len(SR_signalT21)))\n",
    "\n",
    "fmt = '{:>20}:  {}'\n",
    "print(fmt.format('# signal events', Nsig))\n",
    "print(fmt.format('signal significance', len(SR_signalT21[0:Nsig])/len(SR_background_dataT21)**0.5))\n",
    "print(fmt.format('s/b ratio', len(SR_signalT21[0:Nsig])/len(SR_background_dataT21)))\n",
    "\n",
    "n_injectionsT21 = 20\n",
    "SR_signals_to_injectT21 = [None] * n_injectionsT21\n",
    "SB_signals_to_injectT21 = [None] * n_injectionsT21\n",
    "signals_to_testT21 = [None] * n_injectionsT21\n",
    "\n",
    "for i in range(n_injectionsT21):\n",
    "    idx = np.isin(range(len(SR_signalT21)), np.random.choice(SR_signalT21.shape[0], size=Nsig, replace=False))\n",
    "    SR_signals_to_injectT21[i] = SR_signalT21[idx, :]\n",
    "    signals_to_testT21[i] = SR_signalT21[~idx, :]\n",
    "    \n",
    "    idx = np.isin(range(len(SB_signalT21)), np.random.choice(SB_signalT21.shape[0], size=Nsig_SB, replace=False))\n",
    "    SB_signals_to_injectT21[i] = SB_signalT21[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff714c1",
   "metadata": {},
   "source": [
    "## CWoLa T_21\n",
    "\n",
    "With relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a0ab088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m model_cwolaT21\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     40\u001b[0m model_cwolaT21\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 42\u001b[0m hist_cwolaT21 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_cwolaT21\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cwola_trainT21\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_cwola_trainT21\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW_cwola_trainT21\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m scores_cwolaT21 \u001b[38;5;241m=\u001b[39m model_cwolaT21\u001b[38;5;241m.\u001b[39mpredict(X_cwola_valT21[:,\u001b[38;5;241m1\u001b[39m:],batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     47\u001b[0m fpr_cwolaT21, tpr_cwolaT21, _ \u001b[38;5;241m=\u001b[39m roc_curve(Y_cwola_valT21, scores_cwolaT21)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1501\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1492\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1493\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[0;32m   1494\u001b[0m         )\n\u001b[0;32m   1495\u001b[0m     )\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1499\u001b[0m ):\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1501\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1518\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:253\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    249\u001b[0m     sample_weights, sample_weight_modes\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n\u001b[1;32m--> 253\u001b[0m (sample_weights, _, _) \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_partial_sample_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight_modes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_all_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m inputs \u001b[38;5;241m=\u001b[39m pack_x_y_sample_weight(x, y, sample_weights)\n\u001b[0;32m    259\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mint\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    261\u001b[0m )\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py:78\u001b[0m, in \u001b[0;36mhandle_partial_sample_weights\u001b[1;34m(outputs, sample_weights, sample_weight_modes, check_all_flat)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"Adds 1.0 as sample weights for the outputs for which there is no weight.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m  describing the raw sample weights.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m any_sample_weight \u001b[38;5;241m=\u001b[39m sample_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m     76\u001b[0m     w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m sample_weights\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m partial_sample_weight \u001b[38;5;241m=\u001b[39m any_sample_weight \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_sample_weight:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, any_sample_weight, partial_sample_weight\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py:78\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m\"\"\"Adds 1.0 as sample weights for the outputs for which there is no weight.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m  describing the raw sample weights.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m any_sample_weight \u001b[38;5;241m=\u001b[39m sample_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m     76\u001b[0m     w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m sample_weights\n\u001b[0;32m     77\u001b[0m )\n\u001b[1;32m---> 78\u001b[0m partial_sample_weight \u001b[38;5;241m=\u001b[39m any_sample_weight \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m     79\u001b[0m     w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m sample_weights\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_sample_weight:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, any_sample_weight, partial_sample_weight\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py:7321\u001b[0m, in \u001b[0;36m_TensorIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   7319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limit:\n\u001b[0;32m   7320\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m-> 7321\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   7322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   7323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1096\u001b[0m, in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m   1095\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[1;32m-> 1096\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1269\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1267\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[1;32m-> 1269\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1281\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:10671\u001b[0m, in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m  10670\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 10671\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10672\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10673\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10674\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m  10676\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#CWoLa with T21 and relu \n",
    "cwola_rocsT21 = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT21)):\n",
    "    \n",
    "    SR_signal_to_injectT21 = SR_signals_to_injectT21[i]\n",
    "    SB_signal_to_injectT21 = SB_signals_to_injectT21[i]\n",
    "\n",
    "    signal_to_testT21 = signals_to_testT21[i]\n",
    "        \n",
    "    X_cwola_trainT21 = np.concatenate([SR_signal_to_injectT21, SR_background_dataT21, SB_signal_to_injectT21, SB_background_dataT21])\n",
    "    Y_cwola_trainT21 = np.concatenate([np.ones(len(SR_signal_to_injectT21)), np.ones(len(SR_background_dataT21)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT21)), np.zeros(len(SB_background_dataT21))])\n",
    "    \n",
    "    X_cwola_trainT21, Y_cwola_trainT21 = shuffle(X_cwola_trainT21, Y_cwola_trainT21, )\n",
    "\n",
    "    sbmjjT21 = X_cwola_trainT21[:,0]\n",
    "    sb_critT21 = ((sbmjjT21 > SR_low - SB_width)&(sbmjjT21 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT21 = X_cwola_trainT21[sb_critT21]\n",
    "    Y_cwola_trainT21 = Y_cwola_trainT21[sb_critT21]\n",
    "    \n",
    "    w_lowT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] <= SR_low).sum())\n",
    "    w_highT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT21 = np.ones_like(Y_cwola_trainT21)\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] <= SR_low)] = w_lowT21\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] >= SR_high)] = w_highT21\n",
    "    \n",
    "    X_cwola_valT21 = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "    Y_cwola_valT21 = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT21 = Sequential()\n",
    "    model_cwolaT21.add(Dense(64, input_dim=N_inputs, activation='relu')) \n",
    "    model_cwolaT21.add(Dense(64, activation='relu'))\n",
    "    model_cwolaT21.add(Dense(64, activation='relu'))\n",
    "    model_cwolaT21.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT21.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT21 = model_cwolaT21.fit(X_cwola_trainT21[:,1:], Y_cwola_trainT21, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT21)\n",
    "\n",
    "    scores_cwolaT21 = model_cwolaT21.predict(X_cwola_valT21[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT21, tpr_cwolaT21, _ = roc_curve(Y_cwola_valT21, scores_cwolaT21)\n",
    "    cwola_rocsT21 = cwola_rocsT21.append({'fpr': fpr_cwolaT21, 'tpr': tpr_cwolaT21}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850676c",
   "metadata": {},
   "source": [
    "## data preparation CWoLa T_32\n",
    "\n",
    "making it machine-learnable, setting params for ML methods, setting signal significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR_low = 3.3\n",
    "SR_high = 3.7\n",
    "test_size = 0.5\n",
    "EPOCHS=20\n",
    "batch_size = 200\n",
    "\n",
    "def sr_crit(d):\n",
    "    return (d[:,0] < SR_high) & (d[:,0] >= SR_low)\n",
    "\n",
    "bg_srsbT32, bg2_srsbT32, sig_srsbT32 = sr_crit(dataset_bgT32), sr_crit(dataset_bg2T32), sr_crit(dataset_sigT32)\n",
    "\n",
    "SR_background_dataT32 = dataset_bgT32[bg_srsbT32]\n",
    "SB_background_dataT32 = dataset_bgT32[~bg_srsbT32]\n",
    "\n",
    "SR_background_simT32 = dataset_bg2T32[bg2_srsbT32]\n",
    "SB_background_simT32 = dataset_bg2T32[~bg2_srsbT32]\n",
    "\n",
    "SR_signalT32 = dataset_sigT32[sig_srsbT32]\n",
    "SB_signalT32 = dataset_sigT32[~sig_srsbT32]\n",
    "\n",
    "N_inputs = len(SR_background_dataT32.T) - 1\n",
    "\n",
    "\n",
    "((SR_background_dataT32, SR_background_data_fortestT32),\n",
    " (SR_background_simT32, SR_background_sim_fortestT32),\n",
    " (SB_background_dataT32, SB_background_data_fortestT32),\n",
    " (SB_background_simT32, SB_background_sim_fortestT32),\n",
    " ) = [train_test_split(arr, test_size=test_size) for arr in [\n",
    "    SR_background_dataT32, SR_background_simT32,\n",
    "    SB_background_dataT32, SB_background_simT32,\n",
    "]]\n",
    "\n",
    "mn,mx = np.percentile(np.concatenate([SB_background_dataT32, SB_background_simT32, SR_background_dataT32, \n",
    "                                      SR_background_simT32]), [1,99], axis=0)\n",
    "\n",
    "def norm_func(d):\n",
    "    return (d - mn)/(mx - mn)\n",
    "\n",
    "Nsig = 1000\n",
    "Nsig_SB = int(np.round(len(SB_signalT32)*Nsig/len(SR_signalT32)))\n",
    "\n",
    "fmt = '{:>20}:  {}'\n",
    "print(fmt.format('# signal events', Nsig))\n",
    "print(fmt.format('signal significance', len(SR_signalT32[0:Nsig])/len(SR_background_dataT32)**0.5))\n",
    "print(fmt.format('s/b ratio', len(SR_signalT32[0:Nsig])/len(SR_background_dataT32)))\n",
    "\n",
    "n_injectionsT32 = 20\n",
    "SR_signals_to_injectT32 = [None] * n_injectionsT32\n",
    "SB_signals_to_injectT32 = [None] * n_injectionsT32\n",
    "signals_to_testT32 = [None] * n_injectionsT32\n",
    "\n",
    "for i in range(n_injectionsT32):\n",
    "    idx = np.isin(range(len(SR_signalT32)), np.random.choice(SR_signalT32.shape[0], size=Nsig, replace=False))\n",
    "    SR_signals_to_injectT32[i] = SR_signalT32[idx, :]\n",
    "    signals_to_testT32[i] = SR_signalT32[~idx, :]\n",
    "    \n",
    "    idx = np.isin(range(len(SB_signalT32)), np.random.choice(SB_signalT32.shape[0], size=Nsig_SB, replace=False))\n",
    "    SB_signals_to_injectT32[i] = SB_signalT32[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7e137",
   "metadata": {},
   "source": [
    "## CWoLa T_32\n",
    "\n",
    "With relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2052898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWoLa with T32 and relu\n",
    "cwola_rocsT32 = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT32)):\n",
    "    \n",
    "    SR_signal_to_injectT32 = SR_signals_to_injectT32[i]\n",
    "    SB_signal_to_injectT32 = SB_signals_to_injectT32[i]\n",
    "\n",
    "    signal_to_testT32 = signals_to_testT32[i]\n",
    "        \n",
    "    X_cwola_trainT32 = np.concatenate([SR_signal_to_injectT32, SR_background_dataT32, SB_signal_to_injectT32, SB_background_dataT32])\n",
    "    Y_cwola_trainT32 = np.concatenate([np.ones(len(SR_signal_to_injectT32)), np.ones(len(SR_background_dataT32)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT32)), np.zeros(len(SB_background_dataT32))])\n",
    "    \n",
    "    X_cwola_trainT32, Y_cwola_trainT32 = shuffle(X_cwola_trainT32, Y_cwola_trainT32, )\n",
    "\n",
    "    sbmjjT32 = X_cwola_trainT32[:,0]\n",
    "    sb_critT32 = ((sbmjjT32 > SR_low - SB_width)&(sbmjjT32 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT32 = X_cwola_trainT32[sb_critT32]\n",
    "    Y_cwola_trainT32 = Y_cwola_trainT32[sb_critT32]\n",
    "    \n",
    "    w_lowT32 = 0.5*(len(SR_signal_to_injectT32) + len(SR_background_dataT32))/((X_cwola_trainT32[:,0] <= SR_low).sum())\n",
    "    w_highT32 = 0.5*(len(SR_signal_to_injectT32) + len(SR_background_dataT32))/((X_cwola_trainT32[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT32 = np.ones_like(Y_cwola_trainT32)\n",
    "    W_cwola_trainT32[(Y_cwola_trainT32 == 0) & (X_cwola_trainT32[:,0] <= SR_low)] = w_lowT32\n",
    "    W_cwola_trainT32[(Y_cwola_trainT32 == 0) & (X_cwola_trainT32[:,0] >= SR_high)] = w_highT32\n",
    "    \n",
    "    X_cwola_valT32 = np.concatenate([signal_to_testT32,SR_background_data_fortestT32])\n",
    "    Y_cwola_valT32 = np.concatenate([np.ones(len(signal_to_testT32)),np.zeros(len(SR_background_data_fortestT32))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT32 = Sequential()\n",
    "    model_cwolaT32.add(Dense(64, input_dim=N_inputs, activation='relu')) \n",
    "    model_cwolaT32.add(Dense(64, activation='relu'))\n",
    "    model_cwolaT32.add(Dense(64, activation='relu'))\n",
    "    model_cwolaT32.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT32.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT32 = model_cwolaT32.fit(X_cwola_trainT32[:,1:], Y_cwola_trainT32, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT32)\n",
    "\n",
    "    scores_cwolaT32 = model_cwolaT32.predict(X_cwola_valT32[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT32, tpr_cwolaT32, _ = roc_curve(Y_cwola_valT32, scores_cwolaT32)\n",
    "    cwola_rocsT32 = cwola_rocsT32.append({'fpr': fpr_cwolaT32, 'tpr': tpr_cwolaT32}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881f117",
   "metadata": {},
   "outputs": [],
   "source": [
    " with np.errstate(divide='ignore'):\n",
    "    tpr_pts = np.linspace(0, 1, 10000)\n",
    "    \n",
    "    # CWoLa T21\n",
    "    fpr_interp = [None] * len(cwola_rocsT21)\n",
    "\n",
    "    for i, row in cwola_rocsT21.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT21 = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT21 = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT21 = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT21 = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT21 = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT21 = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT21 = np.nanstd(sig_interp, axis=0).data\n",
    "    \n",
    "    \n",
    "    # CWoLa T32\n",
    "    fpr_interp = [None] * len(cwola_rocsT32)\n",
    "\n",
    "    for i, row in cwola_rocsT32.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT32 = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT32 = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT32 = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT32 = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT32 = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT32 = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT32 = np.nanstd(sig_interp, axis=0).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076b86d",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec70b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {'cwola_T21': (cwola_maxT21, cwola_medT21, cwola_minT21, cwola_meanT21, cwola_stdT21, cwola_smeanT21, cwola_sstdT21, {'label':'$T_{21}$', 'color':'blue'}),\n",
    "         'cwola_T32': (cwola_maxT32, cwola_medT32, cwola_minT32, cwola_meanT32, cwola_stdT32, cwola_smeanT32, cwola_sstdT32, {'label':'$T_{32}$', 'color':'red'}),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot without banding\n",
    "mylambda=.5\n",
    "myklambda = 1 #np.round(len(SR_background_data)/len(SR_background_sim), 3)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1])\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim([1,5*1e4])\n",
    "ERR=False\n",
    "#plt.plot(tpr_sup,1./fpr_sup,label=\"Supervised\",color='green')\n",
    "\n",
    "for band in bands:\n",
    "    if band in ['old-sacwola', 'hl-sacwola']:\n",
    "        continue\n",
    "    mu,std = bands[band][3:5]\n",
    "\n",
    "    plt.plot(tpr_pts, mu, **bands[band][-1])\n",
    "    if ERR:\n",
    "        plt.fill_between(tpr_pts, mu - std, mu + std, alpha=.2, color=bands[band][-1]['color'])\n",
    "#plt.plot(tpr_sup,1./tpr_sup,color=\"black\",ls=\":\",label=\"Random\")\n",
    "\n",
    "plt.xlabel(r'Signal Efficiency (True Positive Rate)',fontsize=20)\n",
    "plt.ylabel(r\"Rejection (1/False Positive Rate)\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=15,loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b905d8",
   "metadata": {},
   "source": [
    "With T_21 is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a1341",
   "metadata": {},
   "source": [
    "## selu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWoLa with T21 and selu \n",
    "cwola_rocsT21_selu = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT21)):\n",
    "    \n",
    "    SR_signal_to_injectT21 = SR_signals_to_injectT21[i]\n",
    "    SB_signal_to_injectT21 = SB_signals_to_injectT21[i]\n",
    "\n",
    "    signal_to_testT21 = signals_to_testT21[i]\n",
    "        \n",
    "    X_cwola_trainT21 = np.concatenate([SR_signal_to_injectT21, SR_background_dataT21, SB_signal_to_injectT21, SB_background_dataT21])\n",
    "    Y_cwola_trainT21 = np.concatenate([np.ones(len(SR_signal_to_injectT21)), np.ones(len(SR_background_dataT21)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT21)), np.zeros(len(SB_background_dataT21))])\n",
    "    \n",
    "    X_cwola_trainT21, Y_cwola_trainT21 = shuffle(X_cwola_trainT21, Y_cwola_trainT21, )\n",
    "\n",
    "    sbmjjT21 = X_cwola_trainT21[:,0]\n",
    "    sb_critT21 = ((sbmjjT21 > SR_low - SB_width)&(sbmjjT21 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT21 = X_cwola_trainT21[sb_critT21]\n",
    "    Y_cwola_trainT21 = Y_cwola_trainT21[sb_critT21]\n",
    "    \n",
    "    w_lowT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] <= SR_low).sum())\n",
    "    w_highT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT21 = np.ones_like(Y_cwola_trainT21)\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] <= SR_low)] = w_lowT21\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] >= SR_high)] = w_highT21\n",
    "    \n",
    "    X_cwola_valT21 = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "    Y_cwola_valT21 = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT21_selu = Sequential()\n",
    "    model_cwolaT21_selu.add(Dense(64, input_dim=N_inputs, activation='selu')) \n",
    "    model_cwolaT21_selu.add(Dense(64, activation='selu'))\n",
    "    model_cwolaT21_selu.add(Dense(64, activation='selu'))\n",
    "    model_cwolaT21_selu.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT21_selu.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT21_selu = model_cwolaT21_selu.fit(X_cwola_trainT21[:,1:], Y_cwola_trainT21, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT21)\n",
    "\n",
    "    scores_cwolaT21_selu = model_cwolaT21_selu.predict(X_cwola_valT21[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT21_selu, tpr_cwolaT21_selu, _ = roc_curve(Y_cwola_valT21, scores_cwolaT21_selu)\n",
    "    cwola_rocsT21_selu = cwola_rocsT21_selu.append({'fpr': fpr_cwolaT21_selu, 'tpr': tpr_cwolaT21_selu}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad3078",
   "metadata": {},
   "source": [
    "## elu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWoLa with T21 and elu \n",
    "\n",
    "cwola_rocsT21_elu = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT21)):\n",
    "    \n",
    "    SR_signal_to_injectT21 = SR_signals_to_injectT21[i]\n",
    "    SB_signal_to_injectT21 = SB_signals_to_injectT21[i]\n",
    "\n",
    "    signal_to_testT21 = signals_to_testT21[i]\n",
    "        \n",
    "    X_cwola_trainT21 = np.concatenate([SR_signal_to_injectT21, SR_background_dataT21, SB_signal_to_injectT21, SB_background_dataT21])\n",
    "    Y_cwola_trainT21 = np.concatenate([np.ones(len(SR_signal_to_injectT21)), np.ones(len(SR_background_dataT21)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT21)), np.zeros(len(SB_background_dataT21))])\n",
    "    \n",
    "    X_cwola_trainT21, Y_cwola_trainT21 = shuffle(X_cwola_trainT21, Y_cwola_trainT21, )\n",
    "\n",
    "    sbmjjT21 = X_cwola_trainT21[:,0]\n",
    "    sb_critT21 = ((sbmjjT21 > SR_low - SB_width)&(sbmjjT21 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT21 = X_cwola_trainT21[sb_critT21]\n",
    "    Y_cwola_trainT21 = Y_cwola_trainT21[sb_critT21]\n",
    "    \n",
    "    w_lowT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] <= SR_low).sum())\n",
    "    w_highT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT21 = np.ones_like(Y_cwola_trainT21)\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] <= SR_low)] = w_lowT21\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] >= SR_high)] = w_highT21\n",
    "    \n",
    "    X_cwola_valT21 = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "    Y_cwola_valT21 = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT21_elu = Sequential()\n",
    "    model_cwolaT21_elu.add(Dense(64, input_dim=N_inputs, activation='elu')) \n",
    "    model_cwolaT21_elu.add(Dense(64, activation='elu'))\n",
    "    model_cwolaT21_elu.add(Dense(64, activation='elu'))\n",
    "    model_cwolaT21_elu.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT21_elu.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT21_elu = model_cwolaT21_elu.fit(X_cwola_trainT21[:,1:], Y_cwola_trainT21, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT21)\n",
    "\n",
    "    scores_cwolaT21_elu = model_cwolaT21_elu.predict(X_cwola_valT21[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT21_elu, tpr_cwolaT21_elu, _ = roc_curve(Y_cwola_valT21, scores_cwolaT21_elu)\n",
    "    cwola_rocsT21_elu = cwola_rocsT21_elu.append({'fpr': fpr_cwolaT21_elu, 'tpr': tpr_cwolaT21_elu}, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f9289",
   "metadata": {},
   "source": [
    "## leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWoLa with T21 and leaky relu\n",
    "\n",
    "cwola_rocsT21_lrelu = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT21)):\n",
    "    \n",
    "    SR_signal_to_injectT21 = SR_signals_to_injectT21[i]\n",
    "    SB_signal_to_injectT21 = SB_signals_to_injectT21[i]\n",
    "\n",
    "    signal_to_testT21 = signals_to_testT21[i]\n",
    "        \n",
    "    X_cwola_trainT21 = np.concatenate([SR_signal_to_injectT21, SR_background_dataT21, SB_signal_to_injectT21, SB_background_dataT21])\n",
    "    Y_cwola_trainT21 = np.concatenate([np.ones(len(SR_signal_to_injectT21)), np.ones(len(SR_background_dataT21)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT21)), np.zeros(len(SB_background_dataT21))])\n",
    "    \n",
    "    X_cwola_trainT21, Y_cwola_trainT21 = shuffle(X_cwola_trainT21, Y_cwola_trainT21, )\n",
    "\n",
    "    sbmjjT21 = X_cwola_trainT21[:,0]\n",
    "    sb_critT21 = ((sbmjjT21 > SR_low - SB_width)&(sbmjjT21 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT21 = X_cwola_trainT21[sb_critT21]\n",
    "    Y_cwola_trainT21 = Y_cwola_trainT21[sb_critT21]\n",
    "    \n",
    "    w_lowT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] <= SR_low).sum())\n",
    "    w_highT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT21 = np.ones_like(Y_cwola_trainT21)\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] <= SR_low)] = w_lowT21\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] >= SR_high)] = w_highT21\n",
    "    \n",
    "    X_cwola_valT21 = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "    Y_cwola_valT21 = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT21_lrelu = Sequential()\n",
    "    model_cwolaT21_lrelu.add(Dense(64, input_dim=N_inputs, activation='leaky_relu')) \n",
    "    model_cwolaT21_lrelu.add(Dense(64, activation='leaky_relu'))\n",
    "    model_cwolaT21_lrelu.add(Dense(64, activation='leaky_relu'))\n",
    "    model_cwolaT21_lrelu.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT21_lrelu.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT21_lrelu = model_cwolaT21_lrelu.fit(X_cwola_trainT21[:,1:], Y_cwola_trainT21, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT21)\n",
    "\n",
    "    scores_cwolaT21_lrelu = model_cwolaT21_lrelu.predict(X_cwola_valT21[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT21_lrelu, tpr_cwolaT21_lrelu, _ = roc_curve(Y_cwola_valT21, scores_cwolaT21_lrelu)\n",
    "    cwola_rocsT21_lrelu = cwola_rocsT21_lrelu.append({'fpr': fpr_cwolaT21_lrelu, 'tpr': tpr_cwolaT21_lrelu}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.errstate(divide='ignore'):\n",
    "    tpr_pts = np.linspace(0, 1, 10000)\n",
    "    \n",
    "    # CWoLa T21 selu\n",
    "    fpr_interp = [None] * len(cwola_rocsT21_selu)\n",
    "\n",
    "    for i, row in cwola_rocsT21_selu.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT21_selu = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT21_selu = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT21_selu = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT21_selu = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT21_selu = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT21_selu = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT21_selu = np.nanstd(sig_interp, axis=0).data\n",
    "    \n",
    "    \n",
    "    # CWoLa T21 elu\n",
    "    fpr_interp = [None] * len(cwola_rocsT21_elu)\n",
    "\n",
    "    for i, row in cwola_rocsT21_elu.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT21_elu = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT21_elu = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT21_elu = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT21_elu = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT21_elu = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT21_elu = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT21_elu = np.nanstd(sig_interp, axis=0).data\n",
    "    \n",
    "    \n",
    "    # CWoLa T21 leaky relu\n",
    "    fpr_interp = [None] * len(cwola_rocsT21_lrelu)\n",
    "\n",
    "    for i, row in cwola_rocsT21_lrelu.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT21_lrelu = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT21_lrelu = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT21_lrelu = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT21_lrelu = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT21_lrelu = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT21_lrelu = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT21_lrelu = np.nanstd(sig_interp, axis=0).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d693c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands2 = {'cwola_T21relu': (cwola_maxT21, cwola_medT21, cwola_minT21, cwola_meanT21, cwola_stdT21, cwola_smeanT21, cwola_sstdT21, {'label':'ReLU', 'color':'blue'}),\n",
    "          'cwola_T21selu': (cwola_maxT21_selu, cwola_medT21_selu, cwola_minT21_selu, cwola_meanT21_selu, cwola_stdT21_selu, cwola_smeanT21_selu, cwola_sstdT21_selu, {'label':'SELU', 'color':'red'}),\n",
    "          'cwola_T21elu': (cwola_maxT21_elu, cwola_medT21_elu, cwola_minT21_elu, cwola_meanT21_elu, cwola_stdT21_elu, cwola_smeanT21_elu, cwola_sstdT21_elu, {'label':'ELU', 'color':'orange'}),\n",
    "          'cwola_T21lrelu': (cwola_maxT21_lrelu, cwola_medT21_lrelu, cwola_minT21_lrelu, cwola_meanT21_lrelu, cwola_stdT21_lrelu, cwola_smeanT21_lrelu, cwola_sstdT21_lrelu, {'label':'Leaky ReLU', 'color':'green'}),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot without banding\n",
    "mylambda=.5\n",
    "myklambda = 1 #np.round(len(SR_background_data)/len(SR_background_sim), 3)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1])\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim([1,5*1e4])\n",
    "ERR=False\n",
    "#plt.plot(tpr_sup,1./fpr_sup,label=\"Supervised\",color='green')\n",
    "\n",
    "for band in bands2:\n",
    "    if band in ['old-sacwola', 'hl-sacwola']:\n",
    "        continue\n",
    "    mu,std = bands2[band][3:5]\n",
    "\n",
    "    plt.plot(tpr_pts, mu, **bands2[band][-1])\n",
    "    if ERR:\n",
    "        plt.fill_between(tpr_pts, mu - std, mu + std, alpha=.2, color=bands[band][-1]['color'])\n",
    "#plt.plot(tpr_sup,1./tpr_sup,color=\"black\",ls=\":\",label=\"Random\")\n",
    "\n",
    "plt.xlabel(r'Signal Efficiency (True Positive Rate)',fontsize=20)\n",
    "plt.ylabel(r\"Rejection (1/False Positive Rate)\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=15,loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501321de",
   "metadata": {},
   "source": [
    "## Models for AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial data\n",
    "\n",
    "SR_low = 3.3\n",
    "SR_high = 3.7\n",
    "SB_low = 3.1\n",
    "SB_high = 3.9\n",
    "SB_width = 0.3\n",
    "test_size = 0.5\n",
    "EPOCHS=20\n",
    "batch_size = 200\n",
    "\n",
    "#mylambda=.5\n",
    "myklambda = 1 #np.round(len(SR_background_data)/len(SR_background_sim), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e70d4e",
   "metadata": {},
   "source": [
    "## 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class AUCRecordsL2(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_2lay, aucsSB_foravg_2lay, aucs_foravg_2lay, aucsSB_foravg_2lay, aucs_2lay, aucs_std_2lay, aucsSB_2lay, aucsSB_std_2lay, num_epochs\n",
    "        preds_hold_2lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_2lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_2lay = roc_auc_score(Y_test, preds_hold_2lay)\n",
    "        print(myauc_scan_2lay)\n",
    "        myaucSB_scan_2lay = roc_auc_score(Y_testSB, preds_holdSB_2lay)\n",
    "        print(myaucSB_scan_2lay)\n",
    "        \n",
    "        aucs_foravg_2lay += [myauc_scan_2lay]\n",
    "        print(aucs_foravg_2lay)\n",
    "        aucsSB_foravg_2lay += [myaucSB_scan_2lay]\n",
    "        print(aucsSB_foravg_2lay)\n",
    "        \n",
    "        aucs_2lay+=[np.mean(aucs_foravg_2lay)]\n",
    "        print(aucs_2lay)\n",
    "        aucs_std_2lay += [np.std(aucs_foravg_2lay)]\n",
    "        print(aucs_std_2lay)\n",
    "        aucsSB_2lay+=[np.mean(aucsSB_foravg_2lay)]\n",
    "        print(aucsSB_2lay)\n",
    "        aucsSB_std_2lay += [np.std(aucsSB_foravg_2lay)]\n",
    "        print(aucsSB_std_2lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4934ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_2lay = []\n",
    "    num_epochs = []\n",
    "    aucs_2lay = []\n",
    "    aucs_std_2lay = []\n",
    "    aucsSB_2lay = []\n",
    "    aucsSB_std_2lay = []\n",
    "    aucs_foravg_2lay =[]\n",
    "    aucsSB_foravg_2lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_2lay = Sequential()\n",
    "        model_cwola_scan_2lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_2lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_2lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_2lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_2lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_2lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_2lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_2lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_2lay = X_kcwola_train_2lay[sb_crit]\n",
    "        Y_kcwola_train_2lay = Y_kcwola_train_2lay[sb_crit]\n",
    "        W_kcwola_train_2lay = W_kcwola_train_2lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_2lay, Y_kcwola_train_2lay, W_kcwola_train_2lay = shuffle(X_kcwola_train_2lay, Y_kcwola_train_2lay, \n",
    "                                                                       W_kcwola_train_2lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_2lay.fit(norm_func(X_kcwola_train_2lay)[:,1:],Y_kcwola_train_2lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_2lay, verbose=2, callbacks=[AUCRecordsL2()])\n",
    "\n",
    "        pass\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7784b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_2lay = np.asarray(aucs_2lay)\n",
    "aucs_std_2lay = np.asarray(aucs_std_2lay)\n",
    "\n",
    "aucsSB_2lay = np.asarray(aucsSB_2lay)\n",
    "aucsSB_std_2lay = np.asarray(aucsSB_std_2lay)\n",
    "\n",
    "print(aucs_2lay)\n",
    "print(aucsSB_2lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce38ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_2lay,label=\"Signal versus Background\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucs+aucs_std, aucs-aucs_std, alpha=0.2)\n",
    "plt.plot(num_epochs, aucsSB_2lay,label=\"Background in SR versus SB\",ls=\"--\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucsSB+aucsSB_std, aucsSB-aucsSB_std,alpha=0.2)\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15d09c",
   "metadata": {},
   "source": [
    "## 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL3(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_3lay, aucsSB_foravg_3lay, aucs_foravg_3lay, aucsSB_foravg_3lay, aucs_3lay, aucs_std_3lay, aucsSB_3lay, aucsSB_std_3lay, num_epochs\n",
    "        preds_hold_3lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_3lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_3lay = roc_auc_score(Y_test, preds_hold_3lay)\n",
    "        print(myauc_scan_3lay)\n",
    "        myaucSB_scan_3lay = roc_auc_score(Y_testSB, preds_holdSB_3lay)\n",
    "        print(myaucSB_scan_3lay)\n",
    "        \n",
    "        aucs_foravg_3lay += [myauc_scan_3lay]\n",
    "        print(aucs_foravg_3lay)\n",
    "        aucsSB_foravg_3lay += [myaucSB_scan_3lay]\n",
    "        print(aucsSB_foravg_3lay)\n",
    "        \n",
    "        aucs_3lay+=[np.mean(aucs_foravg_3lay)]\n",
    "        print(aucs_3lay)\n",
    "        aucs_std_3lay += [np.std(aucs_foravg_3lay)]\n",
    "        print(aucs_std_3lay)\n",
    "        aucsSB_3lay+=[np.mean(aucsSB_foravg_3lay)]\n",
    "        print(aucsSB_3lay)\n",
    "        aucsSB_std_3lay += [np.std(aucsSB_foravg_3lay)]\n",
    "        print(aucsSB_std_3lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ad4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_3lay = []\n",
    "    num_epochs = []\n",
    "    aucs_3lay = []\n",
    "    aucs_std_3lay = []\n",
    "    aucsSB_3lay = []\n",
    "    aucsSB_std_3lay = []\n",
    "    aucs_foravg_3lay =[]\n",
    "    aucsSB_foravg_3lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_3lay = Sequential()\n",
    "        model_cwola_scan_3lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_3lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_3lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_3lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_3lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_3lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_3lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_3lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_3lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_3lay = X_kcwola_train_3lay[sb_crit]\n",
    "        Y_kcwola_train_3lay = Y_kcwola_train_3lay[sb_crit]\n",
    "        W_kcwola_train_3lay = W_kcwola_train_3lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_3lay, Y_kcwola_train_3lay, W_kcwola_train_3lay = shuffle(X_kcwola_train_3lay, Y_kcwola_train_3lay, \n",
    "                                                                       W_kcwola_train_3lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_3lay.fit(norm_func(X_kcwola_train_3lay)[:,1:],Y_kcwola_train_3lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_3lay, verbose=2, callbacks=[AUCRecordsL3()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_3lay = np.asarray(aucs_3lay)\n",
    "aucs_std_3lay = np.asarray(aucs_std_3lay)\n",
    "\n",
    "aucsSB_3lay = np.asarray(aucsSB_3lay)\n",
    "aucsSB_std_3lay = np.asarray(aucsSB_std_3lay)\n",
    "\n",
    "print(aucs_3lay)\n",
    "print(aucsSB_3lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_3lay,label=\"Signal versus Background\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucs+aucs_std, aucs-aucs_std, alpha=0.2)\n",
    "plt.plot(num_epochs, aucsSB_3lay,label=\"Background in SR versus SB\",ls=\"--\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucsSB+aucsSB_std, aucsSB-aucsSB_std,alpha=0.2)\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde72f3",
   "metadata": {},
   "source": [
    "## 4 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdcd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL4(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_4lay, aucsSB_foravg_4lay, aucs_foravg_4lay, aucsSB_foravg_4lay, aucs_4lay, aucs_std_4lay, aucsSB_4lay, aucsSB_std_4lay, num_epochs\n",
    "        preds_hold_4lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_4lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_4lay = roc_auc_score(Y_test, preds_hold_4lay)\n",
    "        print(myauc_scan_4lay)\n",
    "        myaucSB_scan_4lay = roc_auc_score(Y_testSB, preds_holdSB_4lay)\n",
    "        print(myaucSB_scan_4lay)\n",
    "        \n",
    "        aucs_foravg_4lay += [myauc_scan_4lay]\n",
    "        print(aucs_foravg_4lay)\n",
    "        aucsSB_foravg_4lay += [myaucSB_scan_4lay]\n",
    "        print(aucsSB_foravg_4lay)\n",
    "        \n",
    "        aucs_4lay+=[np.mean(aucs_foravg_4lay)]\n",
    "        print(aucs_4lay)\n",
    "        aucs_std_4lay += [np.std(aucs_foravg_4lay)]\n",
    "        print(aucs_std_4lay)\n",
    "        aucsSB_4lay+=[np.mean(aucsSB_foravg_4lay)]\n",
    "        print(aucsSB_4lay)\n",
    "        aucsSB_std_4lay += [np.std(aucsSB_foravg_4lay)]\n",
    "        print(aucsSB_std_4lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299fafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_4lay = []\n",
    "    num_epochs = []\n",
    "    aucs_4lay = []\n",
    "    aucs_std_4lay = []\n",
    "    aucsSB_4lay = []\n",
    "    aucsSB_std_4lay = []\n",
    "    aucs_foravg_4lay =[]\n",
    "    aucsSB_foravg_4lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_4lay = Sequential()\n",
    "        model_cwola_scan_4lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_4lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_4lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_4lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_4lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_4lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_4lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_4lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_4lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_4lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_4lay = X_kcwola_train_4lay[sb_crit]\n",
    "        Y_kcwola_train_4lay = Y_kcwola_train_4lay[sb_crit]\n",
    "        W_kcwola_train_4lay = W_kcwola_train_4lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_4lay, Y_kcwola_train_4lay, W_kcwola_train_4lay = shuffle(X_kcwola_train_4lay, Y_kcwola_train_4lay, \n",
    "                                                                       W_kcwola_train_4lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_4lay.fit(norm_func(X_kcwola_train_4lay)[:,1:],Y_kcwola_train_4lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_4lay, verbose=2, callbacks=[AUCRecordsL4()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd897d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_4lay = np.asarray(aucs_4lay)\n",
    "aucs_std_4lay = np.asarray(aucs_std_4lay)\n",
    "\n",
    "aucsSB_4lay = np.asarray(aucsSB_4lay)\n",
    "aucsSB_std_4lay = np.asarray(aucsSB_std_4lay)\n",
    "\n",
    "print(aucs_4lay)\n",
    "print(aucsSB_4lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25427a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_4lay,label=\"Signal versus Background\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucs+aucs_std, aucs-aucs_std, alpha=0.2)\n",
    "plt.plot(num_epochs, aucsSB_4lay,label=\"Background in SR versus SB\",ls=\"--\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucsSB+aucsSB_std, aucsSB-aucsSB_std,alpha=0.2)\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f1630",
   "metadata": {},
   "source": [
    "## 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL5(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_5lay, aucsSB_foravg_5lay, aucs_foravg_5lay, aucsSB_foravg_5lay, aucs_5lay, aucs_std_5lay, aucsSB_5lay, aucsSB_std_5lay, num_epochs\n",
    "        preds_hold_5lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_5lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_5lay = roc_auc_score(Y_test, preds_hold_5lay)\n",
    "        print(myauc_scan_5lay)\n",
    "        myaucSB_scan_5lay = roc_auc_score(Y_testSB, preds_holdSB_5lay)\n",
    "        print(myaucSB_scan_5lay)\n",
    "        \n",
    "        aucs_foravg_5lay += [myauc_scan_5lay]\n",
    "        print(aucs_foravg_5lay)\n",
    "        aucsSB_foravg_5lay += [myaucSB_scan_5lay]\n",
    "        print(aucsSB_foravg_5lay)\n",
    "        \n",
    "        aucs_5lay+=[np.mean(aucs_foravg_5lay)]\n",
    "        print(aucs_5lay)\n",
    "        aucs_std_5lay += [np.std(aucs_foravg_5lay)]\n",
    "        print(aucs_std_5lay)\n",
    "        aucsSB_5lay+=[np.mean(aucsSB_foravg_5lay)]\n",
    "        print(aucsSB_5lay)\n",
    "        aucsSB_std_5lay += [np.std(aucsSB_foravg_5lay)]\n",
    "        print(aucsSB_std_5lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce49218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_5lay = []\n",
    "    num_epochs = []\n",
    "    aucs_5lay = []\n",
    "    aucs_std_5lay = []\n",
    "    aucsSB_5lay = []\n",
    "    aucsSB_std_5lay = []\n",
    "    aucs_foravg_5lay =[]\n",
    "    aucsSB_foravg_5lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_5lay = Sequential()\n",
    "        model_cwola_scan_5lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_5lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_5lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_5lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_5lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_5lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_5lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_5lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_5lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_5lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_5lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_5lay = X_kcwola_train_5lay[sb_crit]\n",
    "        Y_kcwola_train_5lay = Y_kcwola_train_5lay[sb_crit]\n",
    "        W_kcwola_train_5lay = W_kcwola_train_5lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_5lay, Y_kcwola_train_5lay, W_kcwola_train_5lay = shuffle(X_kcwola_train_5lay, Y_kcwola_train_5lay, \n",
    "                                                                       W_kcwola_train_5lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_5lay.fit(norm_func(X_kcwola_train_5lay)[:,1:],Y_kcwola_train_5lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_5lay, verbose=2, callbacks=[AUCRecordsL5()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28963e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_5lay = np.asarray(aucs_5lay)\n",
    "aucs_std_5lay = np.asarray(aucs_std_5lay)\n",
    "\n",
    "aucsSB_5lay = np.asarray(aucsSB_5lay)\n",
    "aucsSB_std_5lay = np.asarray(aucsSB_std_5lay)\n",
    "\n",
    "print(aucs_5lay)\n",
    "print(aucsSB_5lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec09cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_5lay,label=\"Signal versus Background\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucs+aucs_std, aucs-aucs_std, alpha=0.2)\n",
    "plt.plot(num_epochs, aucsSB_5lay,label=\"Background in SR versus SB\",ls=\"--\",linewidth=3)\n",
    "#plt.fill_between(epochs,aucsSB+aucsSB_std, aucsSB-aucsSB_std,alpha=0.2)\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31ab62",
   "metadata": {},
   "source": [
    "# AUC all architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2465d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_2lay,label=\"Signal versus Background Model 2 layers architecture\",linewidth=3,color='red')\n",
    "plt.plot(num_epochs, aucsSB_2lay,label=\"Background in SR versus SB 2 layers architecture\",ls=\"--\",linewidth=3,color='red')\n",
    "\n",
    "plt.plot(num_epochs, aucs_3lay,label=\"Signal versus Background 3 layers architecture\",linewidth=3,color='blue')\n",
    "plt.plot(num_epochs, aucsSB_3lay,label=\"Background in SR versus SB 3 layers architecture\",ls=\"--\",linewidth=3,color='blue')\n",
    "\n",
    "plt.plot(num_epochs, aucs_4lay,label=\"Signal versus Background 4 layers architecture\",linewidth=3,color='green')\n",
    "plt.plot(num_epochs, aucsSB_4lay,label=\"Background in SR versus SB 4 layers architecture\",ls=\"--\",linewidth=3,color='green')\n",
    "\n",
    "plt.plot(num_epochs, aucs_5lay,label=\"Signal versus Background 5 layers architecture\",linewidth=3,color='orange')\n",
    "plt.plot(num_epochs, aucsSB_5lay,label=\"Background in SR versus SB 5 layers architecture\",ls=\"--\",linewidth=3,color='orange')\n",
    "\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20, bbox_to_anchor=(1.05, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ddaf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL15(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_15lay, aucsSB_foravg_15lay, aucs_foravg_15lay, aucsSB_foravg_15lay, aucs_15lay, aucs_std_15lay, aucsSB_15lay, aucsSB_std_15lay, num_epochs\n",
    "        preds_hold_15lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_15lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_15lay = roc_auc_score(Y_test, preds_hold_15lay)\n",
    "        print(myauc_scan_15lay)\n",
    "        myaucSB_scan_15lay = roc_auc_score(Y_testSB, preds_holdSB_15lay)\n",
    "        print(myaucSB_scan_15lay)\n",
    "        \n",
    "        aucs_foravg_15lay += [myauc_scan_15lay]\n",
    "        print(aucs_foravg_15lay)\n",
    "        aucsSB_foravg_15lay += [myaucSB_scan_15lay]\n",
    "        print(aucsSB_foravg_15lay)\n",
    "        \n",
    "        aucs_15lay+=[np.mean(aucs_foravg_15lay)]\n",
    "        print(aucs_15lay)\n",
    "        aucs_std_15lay += [np.std(aucs_foravg_15lay)]\n",
    "        print(aucs_std_15lay)\n",
    "        aucsSB_15lay+=[np.mean(aucsSB_foravg_15lay)]\n",
    "        print(aucsSB_15lay)\n",
    "        aucsSB_std_15lay += [np.std(aucsSB_foravg_15lay)]\n",
    "        print(aucsSB_std_15lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37453e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_15lay = []\n",
    "    num_epochs = []\n",
    "    aucs_15lay = []\n",
    "    aucs_std_15lay = []\n",
    "    aucsSB_15lay = []\n",
    "    aucsSB_std_15lay = []\n",
    "    aucs_foravg_15lay =[]\n",
    "    aucsSB_foravg_15lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_15lay = Sequential()\n",
    "        model_cwola_scan_15lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_15lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_15lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_15lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_15lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_15lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_15lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_15lay = X_kcwola_train_15lay[sb_crit]\n",
    "        Y_kcwola_train_15lay = Y_kcwola_train_15lay[sb_crit]\n",
    "        W_kcwola_train_15lay = W_kcwola_train_15lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_15lay, Y_kcwola_train_15lay, W_kcwola_train_15lay = shuffle(X_kcwola_train_15lay, Y_kcwola_train_15lay, \n",
    "                                                                       W_kcwola_train_15lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_15lay.fit(norm_func(X_kcwola_train_15lay)[:,1:],Y_kcwola_train_15lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_15lay, verbose=2, callbacks=[AUCRecordsL15()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a1b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_15lay = np.asarray(aucs_15lay)\n",
    "aucs_std_15lay = np.asarray(aucs_std_15lay)\n",
    "\n",
    "aucsSB_15lay = np.asarray(aucsSB_15lay)\n",
    "aucsSB_std_15lay = np.asarray(aucsSB_std_15lay)\n",
    "\n",
    "print(aucs_15lay)\n",
    "print(aucsSB_15lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_2lay,label=\"Signal versus Background Model 2 layers architecture\",linewidth=3,color='red')\n",
    "plt.plot(num_epochs, aucsSB_2lay,label=\"Background in SR versus SB 2 layers architecture\",ls=\"--\",linewidth=3,color='red')\n",
    "\n",
    "plt.plot(num_epochs, aucs_3lay,label=\"Signal versus Background 3 layers architecture\",linewidth=3,color='blue')\n",
    "plt.plot(num_epochs, aucsSB_3lay,label=\"Background in SR versus SB 3 layers architecture\",ls=\"--\",linewidth=3,color='blue')\n",
    "\n",
    "plt.plot(num_epochs, aucs_4lay,label=\"Signal versus Background 4 layers architecture\",linewidth=3,color='green')\n",
    "plt.plot(num_epochs, aucsSB_4lay,label=\"Background in SR versus SB 4 layers architecture\",ls=\"--\",linewidth=3,color='green')\n",
    "\n",
    "plt.plot(num_epochs, aucs_5lay,label=\"Signal versus Background 5 layers architecture\",linewidth=3,color='orange')\n",
    "plt.plot(num_epochs, aucsSB_5lay,label=\"Background in SR versus SB 5 layers architecture\",ls=\"--\",linewidth=3,color='orange')\n",
    "\n",
    "plt.plot(num_epochs, aucs_15lay,label=\"Signal versus Background 15 layers architecture\",linewidth=3,color='magenta')\n",
    "plt.plot(num_epochs, aucsSB_15lay,label=\"Background in SR versus SB 15 layers architecture\",ls=\"--\",linewidth=3,color='magenta')\n",
    "\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20, bbox_to_anchor=(1.05, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64873cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL9(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_9lay, aucsSB_foravg_9lay, aucs_foravg_9lay, aucsSB_foravg_9lay, aucs_9lay, aucs_std_9lay, aucsSB_9lay, aucsSB_std_9lay, num_epochs\n",
    "        preds_hold_9lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_9lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_9lay = roc_auc_score(Y_test, preds_hold_9lay)\n",
    "        print(myauc_scan_9lay)\n",
    "        myaucSB_scan_9lay = roc_auc_score(Y_testSB, preds_holdSB_9lay)\n",
    "        print(myaucSB_scan_9lay)\n",
    "        \n",
    "        aucs_foravg_9lay += [myauc_scan_9lay]\n",
    "        print(aucs_foravg_9lay)\n",
    "        aucsSB_foravg_9lay += [myaucSB_scan_9lay]\n",
    "        print(aucsSB_foravg_9lay)\n",
    "        \n",
    "        aucs_9lay+=[np.mean(aucs_foravg_9lay)]\n",
    "        print(aucs_9lay)\n",
    "        aucs_std_9lay += [np.std(aucs_foravg_9lay)]\n",
    "        print(aucs_std_9lay)\n",
    "        aucsSB_9lay+=[np.mean(aucsSB_foravg_9lay)]\n",
    "        print(aucsSB_9lay)\n",
    "        aucsSB_std_9lay += [np.std(aucsSB_foravg_9lay)]\n",
    "        print(aucsSB_std_9lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397afdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_9lay = []\n",
    "    num_epochs = []\n",
    "    aucs_9lay = []\n",
    "    aucs_std_9lay = []\n",
    "    aucsSB_9lay = []\n",
    "    aucsSB_std_9lay = []\n",
    "    aucs_foravg_9lay =[]\n",
    "    aucsSB_foravg_9lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_9lay = Sequential()\n",
    "        model_cwola_scan_9lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_9lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_9lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_9lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_9lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_9lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_9lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_9lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_9lay = X_kcwola_train_9lay[sb_crit]\n",
    "        Y_kcwola_train_9lay = Y_kcwola_train_9lay[sb_crit]\n",
    "        W_kcwola_train_9lay = W_kcwola_train_9lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_9lay, Y_kcwola_train_9lay, W_kcwola_train_9lay = shuffle(X_kcwola_train_9lay, Y_kcwola_train_9lay, \n",
    "                                                                       W_kcwola_train_9lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_9lay.fit(norm_func(X_kcwola_train_9lay)[:,1:],Y_kcwola_train_9lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_9lay, verbose=2, callbacks=[AUCRecordsL9()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_9lay = np.asarray(aucs_9lay)\n",
    "aucs_std_9lay = np.asarray(aucs_std_9lay)\n",
    "\n",
    "aucsSB_9lay = np.asarray(aucsSB_9lay)\n",
    "aucsSB_std_9lay = np.asarray(aucsSB_std_9lay)\n",
    "\n",
    "print(aucs_9lay)\n",
    "print(aucsSB_9lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb592069",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_2lay,label=\"Signal versus Background Model 2 layers architecture\",linewidth=3,color='red')\n",
    "plt.plot(num_epochs, aucsSB_2lay,label=\"Background in SR versus SB 2 layers architecture\",ls=\"--\",linewidth=3,color='red')\n",
    "\n",
    "plt.plot(num_epochs, aucs_3lay,label=\"Signal versus Background 3 layers architecture\",linewidth=3,color='blue')\n",
    "plt.plot(num_epochs, aucsSB_3lay,label=\"Background in SR versus SB 3 layers architecture\",ls=\"--\",linewidth=3,color='blue')\n",
    "\n",
    "plt.plot(num_epochs, aucs_4lay,label=\"Signal versus Background 4 layers architecture\",linewidth=3,color='green')\n",
    "plt.plot(num_epochs, aucsSB_4lay,label=\"Background in SR versus SB 4 layers architecture\",ls=\"--\",linewidth=3,color='green')\n",
    "\n",
    "plt.plot(num_epochs, aucs_5lay,label=\"Signal versus Background 5 layers architecture\",linewidth=3,color='orange')\n",
    "plt.plot(num_epochs, aucsSB_5lay,label=\"Background in SR versus SB 5 layers architecture\",ls=\"--\",linewidth=3,color='orange')\n",
    "\n",
    "plt.plot(num_epochs, aucs_9lay,label=\"Signal versus Background 9 layers architecture\",linewidth=3,color='cyan')\n",
    "plt.plot(num_epochs, aucsSB_9lay,label=\"Background in SR versus SB 9 layers architecture\",ls=\"--\",linewidth=3,color='cyan')\n",
    "\n",
    "plt.plot(num_epochs, aucs_15lay,label=\"Signal versus Background 15 layers architecture\",linewidth=3,color='magenta')\n",
    "plt.plot(num_epochs, aucsSB_15lay,label=\"Background in SR versus SB 15 layers architecture\",ls=\"--\",linewidth=3,color='magenta')\n",
    "\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20, bbox_to_anchor=(1.05, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCRecordsL11(Callback, ):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global aucs_foravg_11lay, aucsSB_foravg_11lay, aucs_foravg_11lay, aucsSB_foravg_11lay, aucs_11lay, aucs_std_11lay, aucsSB_11lay, aucsSB_std_11lay, num_epochs\n",
    "        preds_hold_11lay = self.model.predict(norm_func(X_test)[:,1:],batch_size=10000)[:,0]\n",
    "        preds_holdSB_11lay = self.model.predict(norm_func(X_testSB)[:,1:],batch_size=10000)[:,0]\n",
    "        num_epochs += [epoch]\n",
    "        \n",
    "        myauc_scan_11lay = roc_auc_score(Y_test, preds_hold_11lay)\n",
    "        print(myauc_scan_11lay)\n",
    "        myaucSB_scan_11lay = roc_auc_score(Y_testSB, preds_holdSB_11lay)\n",
    "        print(myaucSB_scan_11lay)\n",
    "        \n",
    "        aucs_foravg_11lay += [myauc_scan_11lay]\n",
    "        print(aucs_foravg_11lay)\n",
    "        aucsSB_foravg_11lay += [myaucSB_scan_11lay]\n",
    "        print(aucsSB_foravg_11lay)\n",
    "        \n",
    "        aucs_11lay+=[np.mean(aucs_foravg_11lay)]\n",
    "        print(aucs_11lay)\n",
    "        aucs_std_11lay += [np.std(aucs_foravg_11lay)]\n",
    "        print(aucs_std_11lay)\n",
    "        aucsSB_11lay+=[np.mean(aucsSB_foravg_11lay)]\n",
    "        print(aucsSB_11lay)\n",
    "        aucsSB_std_11lay += [np.std(aucsSB_foravg_11lay)]\n",
    "        print(aucsSB_std_11lay)\n",
    "        \n",
    "        print(f\"epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0db86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lambdas_11lay = []\n",
    "    num_epochs = []\n",
    "    aucs_11lay = []\n",
    "    aucs_std_11lay = []\n",
    "    aucsSB_11lay = []\n",
    "    aucsSB_std_11lay = []\n",
    "    aucs_foravg_11lay =[]\n",
    "    aucsSB_foravg_11lay = []\n",
    "\n",
    "    for k in range(1):\n",
    "        model_cwola_scan_11lay = Sequential()\n",
    "        model_cwola_scan_11lay.add(Dense(64, input_dim=4, activation='relu')) \n",
    "        model_cwola_scan_11lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(100, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(64, activation='relu'))\n",
    "        model_cwola_scan_11lay.add(Dense(1, activation='sigmoid'))\n",
    "        model_cwola_scan_11lay.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        # Generate training datasets\n",
    "        SR_signal_to_injectT21 = SR_signals_to_injectT21[k]\n",
    "        SB_signal_to_injectT21 = SB_signals_to_injectT21[k]\n",
    "\n",
    "        signal_to_testT21 = signals_to_testT21[k]\n",
    "\n",
    "        X_kcwola_train_11lay = np.concatenate([\n",
    "            SR_signal_to_injectT21, SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] < SR_low], \n",
    "            SB_signal_to_injectT21[SB_signal_to_injectT21[:,0] > SR_high],\n",
    "            SR_background_dataT21, SB_background_dataT21[SB_background_dataT21[:,0] < SR_low], \n",
    "            SB_background_dataT21[SB_background_dataT21[:,0] > SR_high],\n",
    "            SR_background_simT21, SB_background_simT21[SB_background_simT21[:,0] < SR_low], \n",
    "            SB_background_simT21[SB_background_simT21[:,0] > SR_high]\n",
    "        ])\n",
    "        Y_kcwola_train_11lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), np.zeros(len(SB_signal_to_injectT21)),\n",
    "            np.ones(len(SR_background_dataT21)), np.zeros(len(SB_background_dataT21)),\n",
    "            np.zeros(len(SR_background_simT21)), np.ones(len(SB_background_simT21))\n",
    "        ])\n",
    "        \n",
    "        n_low_data = ((SB_background_dataT21[:,0] > (SB_low)) & ((SB_background_dataT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sim = ((SB_background_simT21[:,0] > (SB_low)) & ((SB_background_simT21[:,0] <= SR_low))).sum()\n",
    "        n_low_sig = ((SB_signal_to_injectT21[:,0] > (SB_low)) & ((SB_signal_to_injectT21[:,0] <= SR_low))).sum()\n",
    "\n",
    "        n_hi_data = ((SB_background_dataT21[:,0] < (SB_high)) & ((SB_background_dataT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sim = ((SB_background_simT21[:,0] < (SB_high)) & ((SB_background_simT21[:,0] >= SR_high))).sum()\n",
    "        n_hi_sig = ((SB_signal_to_injectT21[:,0] < (SB_high)) & ((SB_signal_to_injectT21[:,0] >= SR_high))).sum()\n",
    "\n",
    "        n_sr_data = len(SR_background_dataT21)\n",
    "        n_sr_sim = len(SR_background_simT21)\n",
    "        n_sr_sig = len(SR_signal_to_injectT21)\n",
    "\n",
    "        w_low = 0.5*(n_sr_sig + n_sr_data)/(n_low_sig + n_low_data)\n",
    "        w_low_sim = 0.5*(n_sr_sim)/(n_low_sim)\n",
    "\n",
    "        w_high = 0.5*(n_sr_sig + n_sr_data)/(n_hi_sig + n_hi_data)\n",
    "        w_high_sim = 0.5*(n_sr_sim)/(n_hi_sim)\n",
    "        \n",
    "        W_kcwola_train_11lay = np.concatenate([\n",
    "            np.ones(len(SR_signal_to_injectT21)), w_low*np.ones((SB_signal_to_injectT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_signal_to_injectT21[:,0] > SR_high).sum()),\n",
    "            np.ones(len(SR_background_dataT21)), w_low*np.ones((SB_background_dataT21[:,0] <= SR_low).sum()), \n",
    "            w_high*np.ones((SB_background_dataT21[:,0] > SR_high).sum()),\n",
    "            myklambda*np.ones(len(SR_background_simT21)), \n",
    "            w_low_sim*myklambda*np.ones((SB_background_simT21[:,0] <= SR_low).sum()), \n",
    "            w_high_sim*myklambda*np.ones((SB_background_simT21[:,0] > SR_high).sum())\n",
    "        ])\n",
    "    \n",
    "        sbmjj = X_kcwola_train_11lay[:,0]\n",
    "        sb_crit = ((sbmjj > SR_low - SB_width)&(sbmjj <= SR_high + SB_width))\n",
    "\n",
    "        X_kcwola_train_11lay = X_kcwola_train_11lay[sb_crit]\n",
    "        Y_kcwola_train_11lay = Y_kcwola_train_11lay[sb_crit]\n",
    "        W_kcwola_train_11lay = W_kcwola_train_11lay[sb_crit]\n",
    "\n",
    "\n",
    "        X_kcwola_train_11lay, Y_kcwola_train_11lay, W_kcwola_train_11lay = shuffle(X_kcwola_train_11lay, Y_kcwola_train_11lay, \n",
    "                                                                       W_kcwola_train_11lay)\n",
    "\n",
    "    \n",
    "        # Generate testing datasets\n",
    "        X_test = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "        Y_test = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "        \n",
    "        X_testSB = np.concatenate([SR_background_data_fortestT21,SB_background_data_fortestT21])\n",
    "        Y_testSB = np.concatenate([np.ones(len(SR_background_data_fortestT21)),\n",
    "                                   np.zeros(len(SB_background_data_fortestT21))])\n",
    "\n",
    "        model_cwola_scan_11lay.fit(norm_func(X_kcwola_train_11lay)[:,1:],Y_kcwola_train_11lay, epochs=EPOCHS, \n",
    "                               batch_size=batch_size,validation_data=(norm_func(X_test)[:,1:],Y_test),\n",
    "                               sample_weight=W_kcwola_train_11lay, verbose=2, callbacks=[AUCRecordsL11()])\n",
    "\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_11lay = np.asarray(aucs_11lay)\n",
    "aucs_std_11lay = np.asarray(aucs_std_11lay)\n",
    "\n",
    "aucsSB_11lay = np.asarray(aucsSB_11lay)\n",
    "aucsSB_std_11lay = np.asarray(aucsSB_std_11lay)\n",
    "\n",
    "print(aucs_11lay)\n",
    "print(aucsSB_11lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6)) \n",
    "gs = gridspec.GridSpec(1, 1, height_ratios=[1]) \n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.yaxis.set_ticks_position('both')\n",
    "ax0.xaxis.set_ticks_position('both')\n",
    "ax0.tick_params(direction=\"in\",which=\"both\")\n",
    "ax0.minorticks_on()\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.plot(num_epochs, aucs_2lay,label=\"Signal versus Background Model 2 layers architecture\",linewidth=3,color='red')\n",
    "#plt.plot(num_epochs, aucsSB_2lay,label=\"Background in SR versus SB 2 layers architecture\",ls=\"--\",linewidth=3,color='red')\n",
    "\n",
    "plt.plot(num_epochs, aucs_3lay,label=\"Signal versus Background 3 layers architecture\",linewidth=3,color='blue')\n",
    "#plt.plot(num_epochs, aucsSB_3lay,label=\"Background in SR versus SB 3 layers architecture\",ls=\"--\",linewidth=3,color='blue')\n",
    "\n",
    "plt.plot(num_epochs, aucs_4lay,label=\"Signal versus Background 4 layers architecture\",linewidth=3,color='green')\n",
    "#plt.plot(num_epochs, aucsSB_4lay,label=\"Background in SR versus SB 4 layers architecture\",ls=\"--\",linewidth=3,color='green')\n",
    "\n",
    "plt.plot(num_epochs, aucs_5lay,label=\"Signal versus Background 5 layers architecture\",linewidth=3,color='orange')\n",
    "#plt.plot(num_epochs, aucsSB_5lay,label=\"Background in SR versus SB 5 layers architecture\",ls=\"--\",linewidth=3,color='orange')\n",
    "\n",
    "plt.plot(num_epochs, aucs_9lay,label=\"Signal versus Background 9 layers architecture\",linewidth=3,color='cyan')\n",
    "#plt.plot(num_epochs, aucsSB_9lay,label=\"Background in SR versus SB 9 layers architecture\",ls=\"--\",linewidth=3,color='cyan')\n",
    "\n",
    "plt.plot(num_epochs, aucs_11lay,label=\"Signal versus Background 11 layers architecture\",linewidth=3,color='yellow')\n",
    "#plt.plot(num_epochs, aucsSB_11lay,label=\"Background in SR versus SB 11 layers architecture\",ls=\"--\",linewidth=3,color='yellow')\n",
    "\n",
    "#plt.plot(num_epochs, aucs_15lay,label=\"Signal versus Background 15 layers architecture\",linewidth=3,color='magenta')\n",
    "#plt.plot(num_epochs, aucsSB_15lay,label=\"Background in SR versus SB 15 layers architecture\",ls=\"--\",linewidth=3,color='magenta')\n",
    "\n",
    "\n",
    "\n",
    "plt.axhline(0.5,linewidth=2, color='gray',ls=\":\")\n",
    "\n",
    "plt.xlabel(r'Epochs',fontsize=20)\n",
    "plt.ylabel(r\"AUC\",fontsize=20)\n",
    "plt.legend(frameon=False,fontsize=20, bbox_to_anchor=(1.05, 1.0))\n",
    "plt.tight_layout()\n",
    "plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9cdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7729d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808ea16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbaa8fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SR_low = 3.3\n",
    "SR_high = 3.7\n",
    "test_size = 0.5\n",
    "EPOCHS=20\n",
    "batch_size = 200\n",
    "\n",
    "def sr_crit(d):\n",
    "    return (d[:,0] < SR_high) & (d[:,0] >= SR_low)\n",
    "\n",
    "bg_srsbT21, bg2_srsbT21, sig_srsbT21 = sr_crit(dataset_bgT21), sr_crit(dataset_bg2T21), sr_crit(dataset_sigT21)\n",
    "\n",
    "SR_background_dataT21 = dataset_bgT21[bg_srsbT21]\n",
    "SB_background_dataT21 = dataset_bgT21[~bg_srsbT21]\n",
    "\n",
    "SR_background_simT21 = dataset_bg2T21[bg2_srsbT21]\n",
    "SB_background_simT21 = dataset_bg2T21[~bg2_srsbT21]\n",
    "\n",
    "SR_signalT21 = dataset_sigT21[sig_srsbT21]\n",
    "SB_signalT21 = dataset_sigT21[~sig_srsbT21]\n",
    "\n",
    "N_inputs = len(SR_background_dataT21.T) - 1\n",
    "\n",
    "\n",
    "((SR_background_dataT21, SR_background_data_fortestT21),\n",
    " (SR_background_simT21, SR_background_sim_fortestT21),\n",
    " (SB_background_dataT21, SB_background_data_fortestT21),\n",
    " (SB_background_simT21, SB_background_sim_fortestT21),\n",
    " ) = [train_test_split(arr, test_size=test_size) for arr in [\n",
    "    SR_background_dataT21, SR_background_simT21,\n",
    "    SB_background_dataT21, SB_background_simT21,\n",
    "]]\n",
    "\n",
    "mn,mx = np.percentile(np.concatenate([SB_background_dataT21, SB_background_simT21, SR_background_dataT21, \n",
    "                                      SR_background_simT21]), [1,99], axis=0)\n",
    "\n",
    "def norm_func(d):\n",
    "    return (d - mn)/(mx - mn)\n",
    "\n",
    "Nsig = 1000\n",
    "Nsig_SB = int(np.round(len(SB_signalT21)*Nsig/len(SR_signalT21)))\n",
    "\n",
    "fmt = '{:>20}:  {}'\n",
    "print(fmt.format('# signal events', Nsig))\n",
    "print(fmt.format('signal significance', len(SR_signalT21[0:Nsig])/len(SR_background_dataT21)**0.5))\n",
    "print(fmt.format('s/b ratio', len(SR_signalT21[0:Nsig])/len(SR_background_dataT21)))\n",
    "\n",
    "n_injectionsT21 = 20\n",
    "SR_signals_to_injectT21 = [None] * n_injectionsT21\n",
    "SB_signals_to_injectT21 = [None] * n_injectionsT21\n",
    "signals_to_testT21 = [None] * n_injectionsT21\n",
    "\n",
    "for i in range(n_injectionsT21):\n",
    "    idx = np.isin(range(len(SR_signalT21)), np.random.choice(SR_signalT21.shape[0], size=Nsig, replace=False))\n",
    "    SR_signals_to_injectT21[i] = SR_signalT21[idx, :]\n",
    "    signals_to_testT21[i] = SR_signalT21[~idx, :]\n",
    "    \n",
    "    idx = np.isin(range(len(SB_signalT21)), np.random.choice(SB_signalT21.shape[0], size=Nsig_SB, replace=False))\n",
    "    SB_signals_to_injectT21[i] = SB_signalT21[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b94e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CWoLa with T21 and relu \n",
    "cwola_rocsT21 = pd.DataFrame(columns=['fpr', 'tpr'])\n",
    "SB_width = 0.3\n",
    "\n",
    "for i in tqdm.tqdm(range(n_injectionsT21)):\n",
    "    \n",
    "    SR_signal_to_injectT21 = SR_signals_to_injectT21[i]\n",
    "    SB_signal_to_injectT21 = SB_signals_to_injectT21[i]\n",
    "\n",
    "    signal_to_testT21 = signals_to_testT21[i]\n",
    "        \n",
    "    X_cwola_trainT21 = np.concatenate([SR_signal_to_injectT21, SR_background_dataT21, SB_signal_to_injectT21, SB_background_dataT21])\n",
    "    Y_cwola_trainT21 = np.concatenate([np.ones(len(SR_signal_to_injectT21)), np.ones(len(SR_background_dataT21)),\n",
    "                                    np.zeros(len(SB_signal_to_injectT21)), np.zeros(len(SB_background_dataT21))])\n",
    "    \n",
    "    X_cwola_trainT21, Y_cwola_trainT21 = shuffle(X_cwola_trainT21, Y_cwola_trainT21, )\n",
    "\n",
    "    sbmjjT21 = X_cwola_trainT21[:,0]\n",
    "    sb_critT21 = ((sbmjjT21 > SR_low - SB_width)&(sbmjjT21 <= SR_high + SB_width))\n",
    "    \n",
    "    X_cwola_trainT21 = X_cwola_trainT21[sb_critT21]\n",
    "    Y_cwola_trainT21 = Y_cwola_trainT21[sb_critT21]\n",
    "    \n",
    "    w_lowT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] <= SR_low).sum())\n",
    "    w_highT21 = 0.5*(len(SR_signal_to_injectT21) + len(SR_background_dataT21))/((X_cwola_trainT21[:,0] >= SR_high).sum())\n",
    "\n",
    "    W_cwola_trainT21 = np.ones_like(Y_cwola_trainT21)\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] <= SR_low)] = w_lowT21\n",
    "    W_cwola_trainT21[(Y_cwola_trainT21 == 0) & (X_cwola_trainT21[:,0] >= SR_high)] = w_highT21\n",
    "    \n",
    "    X_cwola_valT21 = np.concatenate([signal_to_testT21,SR_background_data_fortestT21])\n",
    "    Y_cwola_valT21 = np.concatenate([np.ones(len(signal_to_testT21)),np.zeros(len(SR_background_data_fortestT21))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model_cwolaT21 = Sequential()\n",
    "    model_cwolaT21.add(Dense(64, input_dim=N_inputs, activation='relu')) \n",
    "    model_cwolaT21.add(Dense(100, activation='relu'))\n",
    "    model_cwolaT21.add(Dense(64, activation='relu'))\n",
    "    model_cwolaT21.add(Dense(100, activation='relu'))\n",
    "    model_cwolaT21.add(Dense(1, activation='sigmoid'))\n",
    "    model_cwolaT21.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    hist_cwolaT21 = model_cwolaT21.fit(X_cwola_trainT21[:,1:], Y_cwola_trainT21, epochs=EPOCHS, \n",
    "                                 batch_size=batch_size, verbose=0, sample_weight=W_cwola_trainT21)\n",
    "\n",
    "    scores_cwolaT21 = model_cwolaT21.predict(X_cwola_valT21[:,1:],batch_size=batch_size)\n",
    "        \n",
    "    fpr_cwolaT21, tpr_cwolaT21, _ = roc_curve(Y_cwola_valT21, scores_cwolaT21)\n",
    "    cwola_rocsT21 = cwola_rocsT21.append({'fpr': fpr_cwolaT21, 'tpr': tpr_cwolaT21}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238c475",
   "metadata": {},
   "outputs": [],
   "source": [
    " with np.errstate(divide='ignore'):\n",
    "    tpr_pts = np.linspace(0, 1, 10000)\n",
    "    \n",
    "    # CWoLa T21\n",
    "    fpr_interp = [None] * len(cwola_rocsT21)\n",
    "\n",
    "    for i, row in cwola_rocsT21.iterrows():\n",
    "        fpr, tpr = row\n",
    "        interp = interpolate.interp1d(tpr, fpr, fill_value=float('nan'), bounds_error=False, assume_sorted=True)\n",
    "\n",
    "        fpr_pts = interp(tpr_pts)\n",
    "        fpr_interp[i] = fpr_pts\n",
    "\n",
    "    fpr_interp = np.ma.masked_invalid(1./np.array(fpr_interp))\n",
    "\n",
    "    cwola_maxT21 = np.nanmax(fpr_interp, axis=0).data\n",
    "    cwola_minT21 = np.nanmin(fpr_interp, axis=0).data\n",
    "    cwola_medT21 = np.median(fpr_interp, axis=0).data\n",
    "    cwola_meanT21 = np.nanmean(fpr_interp, axis=0).data\n",
    "    cwola_stdT21 = np.nanstd(fpr_interp, axis=0).data\n",
    "    \n",
    "    sig_interp = np.ma.masked_invalid(np.sqrt(fpr_interp))\n",
    "    \n",
    "    cwola_smeanT21 = np.nanmean(sig_interp, axis=0).data\n",
    "    cwola_sstdT21 = np.nanstd(sig_interp, axis=0).data\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be07e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_T21 = {'cwola_T21': (cwola_maxT21, cwola_medT21, cwola_minT21, cwola_meanT21, cwola_stdT21, cwola_smeanT21, cwola_sstdT21, {'label':'$T_{21}$', 'color':'blue'}),}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
